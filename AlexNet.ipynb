{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17vYxed13NJy833F-5Ejup0dIvW1ObNcC","authorship_tag":"ABX9TyMKa3YUxbg8o/dCj2TtWzdY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/model.py#L40"],"metadata":{"id":"lbBz9Itz0COq"}},{"cell_type":"code","source":["!pip install tensorboardx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuyOHrDD4QXK","executionInfo":{"status":"ok","timestamp":1724326389295,"user_tz":-540,"elapsed":13552,"user":{"displayName":"SAP A","userId":"14199498762077628595"}},"outputId":"8b959e0f-b0eb-449b-8deb-fc1ad2889ec0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardx\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboardx\n","Successfully installed tensorboardx-2.6.2.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb180bXW3Cyw","executionInfo":{"status":"ok","timestamp":1724326399422,"user_tz":-540,"elapsed":10131,"user":{"displayName":"SAP A","userId":"14199498762077628595"}},"outputId":"d9e5348f-f215-4a2b-ee4b-5f3ce7ebee36"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# 패키지 설치\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils import data\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from tensorboardX import SummaryWriter\n","# define pytorch device - useful for device-agnostic execution\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# define model parameters\n","NUM_EPOCHS = 90\n","BATCH_SIZE = 128\n","MOMENTUM = 0.9\n","LR_DECAY = 0.0005\n","LR_INIT = 0.01\n","IMAGE_DIM = 227\n","NUM_CLASSES = 1000\n","DEVICE_IDS = [0,1,2,3] # GPUs to use\n","# modify this to point to your data directory\n","INPUT_ROOT_DIR = 'alexnet_data_in'\n","TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n","OUTPUT_DIR = 'alexnet_data_out'\n","LOG_DIR = OUTPUT_DIR + '/tblogs' # tensorboard logs\n","CHECKPOINT_DIR = OUTPUT_DIR + '/models' # model checkpoints\n","PATH = './drive/MyDrive/Colab Notebooks'\n","os.chdir(PATH)\n","os.makedirs(CHECKPOINT_DIR, exist_ok = True) # alexnet_data_out/models 파일을 만듬, exist_ok = True는 이미 폴더가 만들어져있어도 오류 X\n"],"metadata":{"id":"lJ7UB6vD0KWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Aj8IO4XN8Ywr","executionInfo":{"status":"ok","timestamp":1723255605401,"user_tz":-540,"elapsed":325,"user":{"displayName":"SAP A","userId":"14199498762077628595"}},"outputId":"7cdb7b36-d5f1-4fec-c0ed-e7997e322c1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class AlexNet(nn.Module):\n","\n","  def __init__(self, num_classes=1000): # 1000개의 클래스를 예측\n","    super().__init__()\n","    # ouput_dim(i,j) = np.floor((input_dim(i,j) - kernel_size + 2 x padding_size ) / stride) + 1\n","    self.net = nn.Sequential( # (batch_size x 3 x 227 x 227)\n","        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4), # (batch_size x 96 x 55 x 55)\n","        nn.Relu(), # max(0,x)\n","        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2), # ouput feature map에 있는 픽셀 A(x,y)의 값을 인접한 픽셀들의 값을 합한 값으로 나눠줌\n","        nn.MaxPool2d(kernel_size=3, stride=2), # (b x 96 x 27 x 27), 커널안에 있는 최대값만 뽑아냄\n","        nn.Conv2d(96,256,5,padding=2),  # (b x 256 x 27 x 27), kernel_size = 2 x padding_size + 1 이고 stride = 1 이라 same padding임\n","        nn.Relu(),\n","        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n","        nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 13 x 13)\n","        nn.Conv2d(256, 384, 3, padding=1), # (b x 384 x 13 x 13), same padding\n","        nn.Relu(),\n","        nn.Conv2d(384, 384, 3, padding=1), # (b x 384 x 13 x 13), same padding\n","        nn.Relu(),\n","        nn.Conv2d(384, 256, 3, padding=1), # (b x 256 x 13 x 13), same padding\n","        nn.Relu(),\n","        nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n","    )\n","    self.classifie = nn.Sequential(\n","        nn.Dropout(p=0.5, inplace=True), # inplace란 원본데이터에도 Dropout을 반영하는지 여부\n","        nn.Linear(in_features=(256 * 6 * 6), out_features=4096), # (b x 4096), 여기선 keras와 달리 flatten을 어떻게 해주는지 모르겠음)\n","        nn.Relu(),\n","        nn.Dropout(p=0.5, inplace=True),\n","        nn.Linear(in_features=4096, out_features=4096),\n","        nn.Relu(),\n","        nn.Linear(in_features=4096, out_features=num_classes),\n","    )\n","    self.init_bias()\n","\n","  def init_bias(self):\n","    for layer in self.net:\n","      if isinstance(layer, nn.Conv2d): # isinstance(인스턴스, 데이터나 클래스 타입)\n","        nn.init.normal_(layer.weight, mean=0, std=0.01)\n","        nn.init.constant_(layer.bias, 0) # constant_(텐서, float), float으로 텐서를 채움\n","  # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n","\n","    nn.init.constant_(self.net[4].bias, 1)\n","    nn.init.constant_(self.net[10].bias, 1)\n","    nn.init.constant_(self.net[12].bias, 1)\n","\n","  def forward(self, x):\n","    # 정방향패스\n","\n","    x = self.net(x)\n","    x = x.view(-1, 256*6*6)\n","    return self.classifer(x)\n","\n","\n","if __name__ == '__main__':\n","  seed = torch.inital_seed()\n","  print('Used seed : {}'.format(seed))\n","\n","  tbwriter = SummaryWriter(log_dir=LOG_DIR)\n","  print('TensorboardX summary writer created')\n","\n","  alexnet = AlexNet(num_classes=NUM_CLASSES).to(device) # 모델을 device(cuda)에 넣음\n"," # train on multiple GPUs\n","  alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids =DEVICE_IDS)\n","\n","  print(alexnet)\n","  print('Alexnet created')\n","\n","# create dataset and data loader\n","  dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n","       # transforms.RandomResizedCrop(IMAGE_DIM, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n","       transforms.CenterCrop(IMAGE_DIM),\n","       # transforms.RandomHorizontalFlip(),\n","       transforms.ToTensor(),\n","       transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","  ]))\n","  print('Dataset created')\n","  dataloader = data.DataLoader(\n","      dataset,\n","      shuffle=True,\n","      pin_memory=True,\n","      num_workers=8,\n","      drop_last=True,\n","      batch_size=BATCH_SIZE)\n","  print('Dataloader created')\n","\n","  # create optimizer\n","  # the one that WORKS\n","\n","  optimizer = optim.Adam(params=alexnet.parameters(), lr=0.0001)\n","  ### BELOW is the setting proposed by the original paper - which doesn't train....\n","    # optimizer = optim.SGD(\n","    #     params=alexnet.parameters(),\n","    #     lr=LR_INIT,\n","    #     momentum=MOMENTUM,\n","    #     weight_decay=LR_DECAY)\n","  print('Optimizer created')\n","  # multiply LR by 1 / 10 after every 30 epochs\n","\n","  lr_scheduler = optim.lr_scheduler.StepLR(optimizier, step_size=30, gamma=0.1)\n","\n","\n","\n","\n"],"metadata":{"id":"zlVyq9Vy8bav"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Drszh2oL4tC0"}},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"fsuEg5JgHfHl","executionInfo":{"status":"error","timestamp":1723357600084,"user_tz":-540,"elapsed":326,"user":{"displayName":"SAP A","userId":"14199498762077628595"}},"outputId":"eb9f3c28-d785-4638-d8d9-d86c393a6af7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'x' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-191ea9c3d109>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ta6nn_g_HhZT"},"execution_count":null,"outputs":[]}]}